from abc import ABC, abstractmethod
from typing import List, Optional, Dict, Any
import asyncio
from models.product import Product
from utils.browser import BrowserManager
from utils.helpers import random_delay
from config.settings import Settings

class BaseScraper(ABC):
    """Clase base para todos los scrapers"""
    
    def __init__(self, mobile: bool = False, device: Optional[str] = None):
        self.mobile = mobile
        self.device = device
        self.browser_manager = BrowserManager(mobile=mobile)
        self.marketplace_name = ""
        self.base_url = ""
        self.products: List[Product] = []
    
    @abstractmethod
    async def build_search_url(self, query: str, **kwargs) -> str:
        """Construye la URL de b√∫squeda"""
        pass
    
    @abstractmethod
    async def extract_product_info(self, element) -> Optional[Product]:
        """Extrae informaci√≥n de un producto desde un elemento HTML"""
        pass
    
    @abstractmethod
    async def get_product_elements(self):
        """Obtiene los elementos de productos de la p√°gina"""
        pass
    
    @abstractmethod
    async def post_navigate_validation(self) -> bool:
        """
        Ejecuta validaciones y manejo de elementos despu√©s de navegar a una p√°gina.
        
        Este m√©todo debe ser implementado por cada scraper espec√≠fico para manejar:
        - Popups de ubicaci√≥n, cookies, etc.
        - Modales de autenticaci√≥n
        - Captchas
        - Elementos que bloqueen el contenido
        - Validaciones espec√≠ficas del marketplace
        
        Returns:
            bool: True si la p√°gina est√° lista para scraping, False si hay errores cr√≠ticos
        """
        pass
    
    async def search_products(self, query: str, max_pages: int = 1, **kwargs) -> List[Product]:
        """Busca productos por query"""
        self.products = []
        
        try:
            # Iniciar navegador
            await self.browser_manager.start()
            
            for page_num in range(1, max_pages + 1):
                print(f"üìÑ Scrapeando p√°gina {page_num} de üåê {self.marketplace_name}")
                
                # Construir URL
                search_url = await self.build_search_url(query, page=page_num, **kwargs)
                print(f"URL: {search_url}")
                
                # Navegar a la p√°gina
                success = await self.browser_manager.goto(search_url)
                if not success:
                    print(f"Error cargando p√°gina {page_num}")
                    continue
                
                # Ejecutar validaciones post-navegaci√≥n
                print(f"üß≠ Ejecutando validaciones post-navegaci√≥n para {self.marketplace_name}")
                validation_success = await self.post_navigate_validation()
                
                if not validation_success:
                    print(f"‚ùå Fall√≥ la validaci√≥n post-navegaci√≥n en p√°gina {page_num}")
                    # Puedes decidir si continuar o saltar esta p√°gina
                    continue                
                
                
                # Esperar a que cargue el contenido
                await asyncio.sleep(Settings.REQUEST_DELAYS['page_delay'])
                
                # Obtener productos de la p√°gina
                page_products = await self.scrape_current_page()
                
                if not page_products:
                    print(f"‚ö†Ô∏è No se encontraron productos en p√°gina {page_num}")
                    break
                
                self.products.extend(page_products)
                print(f"Productos encontrados en p√°gina {page_num}: {len(page_products)}")
                
                # Delay entre p√°ginas
                if page_num < max_pages:
                    random_delay(
                        Settings.REQUEST_DELAYS['min_delay'],
                        Settings.REQUEST_DELAYS['max_delay']
                    )
            
        except Exception as e:
            print(f"‚ùå Error en b√∫squeda: {e}")
        
        finally:
            await self.browser_manager.close()
        
        print(f"Total productos encontrados: {len(self.products)}")
        return self.products
    
    async def scrape_current_page(self) -> List[Product]:
        """Scrapea la p√°gina actual"""
        products = []
        
        try:
            # Obtener elementos de productos
            product_elements = await self.get_product_elements()
            
            if not product_elements:
                return products
                        
            print(f"== üî¢ Se encontraron {len(product_elements)} elementos de productos == ")
            print("üöÄ Iniciando extracci√≥n de productos...")
            
            # Extraer informaci√≥n de cada producto
            for element in product_elements:
                try:
                    product = await self.extract_product_info(element)
                    if product:
                        product.marketplace = self.marketplace_name
                        products.append(product)
                except Exception as e:
                    print(f"Error extrayendo producto: {e}")
                    continue
                
            print("== üéâ Extracci√≥n de productos completada == ")        
        except Exception as e:
            print(f"Error scrapeando p√°gina: {e}")
        
        return products
    
    async def scroll_and_load(self):
        """Hacer scroll para cargar m√°s productos (√∫til para sitios con scroll infinito)"""
        await self.browser_manager.scroll_to_bottom()